{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## load day-vectors\n",
    "fp = Path(\"tmp_data/agg_day.parquet\")\n",
    "df = pl.read_parquet(fp)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pl.DataFrame,\n",
    "        train_ratio: float = 0.7,\n",
    "        shuffle_init: bool = True,\n",
    "        target: str = \"weekday\",\n",
    "        seed: int | None = None,\n",
    "    ) -> None:\n",
    "        # validation\n",
    "        assert \"date\" in df.columns\n",
    "        self.features = df.drop(\"date\").columns\n",
    "\n",
    "        # optionally shuffle\n",
    "        if shuffle_init:\n",
    "            df = df.sample(len(df), shuffle=True, seed=seed)\n",
    "        self.shuffle_init = shuffle_init\n",
    "\n",
    "        if target == \"weekday\":\n",
    "            self.df = df.with_columns(label=pl.col(\"date\").dt.weekday())\n",
    "        else:\n",
    "            raise ValueError(f\"unknown target: {target}\")\n",
    "\n",
    "        self.ntrain = int(train_ratio * len(df))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        nval = len(self) - self.ntrain\n",
    "        s = f\"dataset: {len(self)} records ({self.ntrain} train, {nval} val)\"\n",
    "\n",
    "        if self.shuffle_init:\n",
    "            s += \" (shuffled)\"\n",
    "        return s\n",
    "\n",
    "    def preprocessed(self, normalize=True, pca_dim: int | None = None):\n",
    "        # split\n",
    "        dfs = {\n",
    "            \"train\": self.df.slice(0, self.ntrain),\n",
    "            \"val\": self.df.slice(self.ntrain),\n",
    "        }\n",
    "        Xs = {k: dfs[k].select(self.features).to_numpy() for k in dfs}\n",
    "        Ys = {k: dfs[k][\"label\"].to_numpy() for k in dfs}\n",
    "\n",
    "        if normalize:\n",
    "            xmin, xmax = Xs[\"train\"].min().item(), Xs[\"train\"].max().item()\n",
    "            print(f\"Normalize (Xtrain-> {xmin=}, {xmax=})\")\n",
    "            Xs = {k: (Xs[k] - xmin) / xmax for k in Xs}\n",
    "\n",
    "        if pca_dim is not None:\n",
    "            pca = PCA(pca_dim)\n",
    "            pca.fit(Xs[\"train\"])\n",
    "            Xs = {k: pca.transform(Xs[k]) for k in Xs}\n",
    "\n",
    "        return {k: (Xs[k], Ys[k]) for k in dfs}\n",
    "\n",
    "\n",
    "data = Dataset(df, seed=1337)\n",
    "print(data)\n",
    "\n",
    "splits = data.preprocessed(pca_dim=24)\n",
    "for s, (x, y) in splits.items():\n",
    "    print(f\"{s}:  {x.shape}, {y.shape}\")\n",
    "print(splits[\"train\"][0].mean())\n",
    "print(splits[\"train\"][1].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c45432",
   "metadata": {},
   "source": [
    "# LogReg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67268c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegressionCV(Cs=list(np.linspace(0.1, 10, 7)))\n",
    "clf.fit(*splits[\"train\"])\n",
    "\n",
    "for k in splits:\n",
    "    acc = clf.score(*splits[k])\n",
    "    print(f\"score({k})= {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d036c909",
   "metadata": {},
   "source": [
    "## LGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction task\n",
    "ld_train = lgb.Dataset(*splits[\"train\"], feature_name=data.features)\n",
    "ld_val = lgb.Dataset(*splits[\"val\"], reference=ld_train, feature_name=data.features)\n",
    "# model\n",
    "params = {\n",
    "    \"num_leaves\": 2,\n",
    "    \"max_depth\": 2,\n",
    "    \"reg_alpha\": 0.5,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    \"n_estimators\": 50,\n",
    "}\n",
    "clf = lgb.LGBMClassifier(force_row_wise=True, **params)  # pyright: ignore[reportGeneralTypeIssues]\n",
    "clf.fit(*splits[\"train\"])\n",
    "\n",
    "# preds = {k: clf.predict(splits[k][0]) for k in splits}  # pyright: ignore[reportAttributeAccessIssue]\n",
    "\n",
    "for k in splits:\n",
    "    acc = clf.score(*splits[k])  # pyright: ignore[reportAttributeAccessIssue]\n",
    "    print(f\"score({k})= {acc:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mango",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
